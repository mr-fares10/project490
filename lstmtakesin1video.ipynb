{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMx2s+2/ziTmPPPelnnVf0O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mr-fares10/project490/blob/main/lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ltVexPRlqXwp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P03T00z1pJpt"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "class JetPositionPredictor:\n",
        "    def __init__(self, sequence_length=10):\n",
        "        \"\"\"\n",
        "        Initialize the jet position predictor\n",
        "\n",
        "        Args:\n",
        "            sequence_length: Number of past frames to use for prediction\n",
        "        \"\"\"\n",
        "        self.sequence_length = sequence_length\n",
        "        self.model = None\n",
        "        self.scaler = MinMaxScaler()\n",
        "\n",
        "    def extract_frames(self, video_path):\n",
        "        \"\"\"\n",
        "        Extract frames from video file\n",
        "\n",
        "        Args:\n",
        "            video_path: Path to video file\n",
        "\n",
        "        Returns:\n",
        "            List of frames\n",
        "        \"\"\"\n",
        "        frames = []\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "        while cap.isOpened():\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "            frames.append(frame)\n",
        "\n",
        "        cap.release()\n",
        "        return frames\n",
        "\n",
        "    def detect_jet_centers(self, frames):\n",
        "        \"\"\"\n",
        "        Detect the center of the jet in each frame\n",
        "        This is a placeholder for your existing jet center detection code\n",
        "\n",
        "        Args:\n",
        "            frames: List of video frames\n",
        "\n",
        "        Returns:\n",
        "            Array of jet center coordinates (x, y, z) for each frame\n",
        "        \"\"\"\n",
        "        # Replace this with your actual jet detection code\n",
        "        centers = []\n",
        "\n",
        "        for frame in frames:\n",
        "            # Example placeholder for detection\n",
        "            # This should be replaced with your actual detection algorithm\n",
        "            center = self.detect_jet_center_in_frame(frame)\n",
        "            centers.append(center)\n",
        "\n",
        "        return np.array(centers)\n",
        "\n",
        "    def detect_jet_center_in_frame(self, frame):\n",
        "        \"\"\"\n",
        "        Placeholder for your existing jet center detection in a single frame\n",
        "\n",
        "        Args:\n",
        "            frame: Single video frame\n",
        "\n",
        "        Returns:\n",
        "            (x, y, z) coordinates of jet center\n",
        "        \"\"\"\n",
        "        # Replace with your actual jet center detection code\n",
        "        # This is just a placeholder\n",
        "        # Assuming your existing code extracts (x, y, z) coordinates\n",
        "        return [0, 0, 0]  # Replace with actual detection\n",
        "\n",
        "    def create_sequences(self, positions):\n",
        "        \"\"\"\n",
        "        Create sequences for LSTM training\n",
        "\n",
        "        Args:\n",
        "            positions: Array of (x, y, z) positions from each frame\n",
        "\n",
        "        Returns:\n",
        "            X: Input sequences\n",
        "            y: Target positions (next frame)\n",
        "        \"\"\"\n",
        "        X, y = [], []\n",
        "\n",
        "        # Scale the data\n",
        "        scaled_positions = self.scaler.fit_transform(positions)\n",
        "\n",
        "        for i in range(len(scaled_positions) - self.sequence_length):\n",
        "            X.append(scaled_positions[i:i + self.sequence_length])\n",
        "            y.append(scaled_positions[i + self.sequence_length])\n",
        "\n",
        "        return np.array(X), np.array(y)\n",
        "\n",
        "    def build_model(self, input_shape):\n",
        "        \"\"\"\n",
        "        Build the LSTM model\n",
        "\n",
        "        Args:\n",
        "            input_shape: Shape of input sequences\n",
        "\n",
        "        Returns:\n",
        "            Compiled LSTM model\n",
        "        \"\"\"\n",
        "        model = Sequential()\n",
        "\n",
        "        # LSTM layers\n",
        "        model.add(LSTM(64, activation='relu', input_shape=input_shape, return_sequences=True))\n",
        "        model.add(Dropout(0.2))\n",
        "\n",
        "        model.add(LSTM(64, activation='relu'))\n",
        "        model.add(Dropout(0.2))\n",
        "\n",
        "        # Output layer (x, y, z)\n",
        "        model.add(Dense(3))\n",
        "\n",
        "        # Compile the model\n",
        "        model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "        self.model = model\n",
        "        return model\n",
        "\n",
        "    def train(self, X, y, epochs=50, batch_size=32, validation_split=0.2):\n",
        "        \"\"\"\n",
        "        Train the LSTM model\n",
        "\n",
        "        Args:\n",
        "            X: Input sequences\n",
        "            y: Target positions\n",
        "            epochs: Number of training epochs\n",
        "            batch_size: Batch size\n",
        "            validation_split: Validation data fraction\n",
        "\n",
        "        Returns:\n",
        "            Training history\n",
        "        \"\"\"\n",
        "        if self.model is None:\n",
        "            self.build_model(X.shape[1:])\n",
        "\n",
        "        history = self.model.fit(\n",
        "            X, y,\n",
        "            epochs=epochs,\n",
        "            batch_size=batch_size,\n",
        "            validation_split=validation_split,\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        return history\n",
        "\n",
        "    def predict_next_position(self, sequence):\n",
        "        \"\"\"\n",
        "        Predict the next position based on a sequence of positions\n",
        "\n",
        "        Args:\n",
        "            sequence: Sequence of recent positions\n",
        "\n",
        "        Returns:\n",
        "            Predicted next (x, y, z) position\n",
        "        \"\"\"\n",
        "        if self.model is None:\n",
        "            raise ValueError(\"Model has not been trained yet\")\n",
        "\n",
        "        # Scale the input sequence\n",
        "        scaled_sequence = self.scaler.transform(sequence)\n",
        "\n",
        "        # Reshape for prediction\n",
        "        scaled_sequence = scaled_sequence.reshape(1, self.sequence_length, 3)\n",
        "\n",
        "        # Predict and inverse transform\n",
        "        scaled_prediction = self.model.predict(scaled_sequence)\n",
        "        prediction = self.scaler.inverse_transform(scaled_prediction)\n",
        "\n",
        "        return prediction[0]\n",
        "\n",
        "    def evaluate_predictions(self, test_video_path):\n",
        "        \"\"\"\n",
        "        Evaluate predictions on a test video\n",
        "\n",
        "        Args:\n",
        "            test_video_path: Path to test video\n",
        "\n",
        "        Returns:\n",
        "            Mean squared error between predictions and actual positions\n",
        "        \"\"\"\n",
        "        # Extract frames and detect centers\n",
        "        frames = self.extract_frames(test_video_path)\n",
        "        actual_positions = self.detect_jet_centers(frames)\n",
        "\n",
        "        # Make predictions\n",
        "        predicted_positions = []\n",
        "\n",
        "        for i in range(self.sequence_length, len(actual_positions)):\n",
        "            sequence = actual_positions[i - self.sequence_length:i]\n",
        "            predicted_pos = self.predict_next_position(sequence)\n",
        "            predicted_positions.append(predicted_pos)\n",
        "\n",
        "        # Calculate error\n",
        "        actual = actual_positions[self.sequence_length:]\n",
        "        predicted = np.array(predicted_positions)\n",
        "\n",
        "        mse = np.mean(np.square(actual - predicted))\n",
        "        print(f\"Mean Squared Error: {mse}\")\n",
        "\n",
        "        # Visualize results\n",
        "        self.visualize_predictions(actual, predicted)\n",
        "\n",
        "        return mse\n",
        "\n",
        "    def visualize_predictions(self, actual, predicted):\n",
        "        \"\"\"\n",
        "        Visualize the actual vs predicted positions\n",
        "\n",
        "        Args:\n",
        "            actual: Actual positions\n",
        "            predicted: Predicted positions\n",
        "        \"\"\"\n",
        "        # Plot actual vs predicted for each dimension\n",
        "        dims = ['X', 'Y', 'Z']\n",
        "\n",
        "        plt.figure(figsize=(15, 10))\n",
        "\n",
        "        for i in range(3):\n",
        "            plt.subplot(3, 1, i+1)\n",
        "            plt.plot(actual[:, i], label='Actual')\n",
        "            plt.plot(predicted[:, i], label='Predicted')\n",
        "            plt.title(f'{dims[i]} Position')\n",
        "            plt.xlabel('Frame')\n",
        "            plt.ylabel('Position')\n",
        "            plt.legend()\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('position_predictions.png')\n",
        "        plt.show()\n",
        "\n",
        "    def save_model(self, filepath):\n",
        "        \"\"\"\n",
        "        Save the trained model\n",
        "\n",
        "        Args:\n",
        "            filepath: Path to save the model\n",
        "        \"\"\"\n",
        "        if self.model is None:\n",
        "            raise ValueError(\"No model to save\")\n",
        "\n",
        "        self.model.save(filepath)\n",
        "\n",
        "    def load_model(self, filepath):\n",
        "        \"\"\"\n",
        "        Load a trained model\n",
        "\n",
        "        Args:\n",
        "            filepath: Path to the trained model\n",
        "        \"\"\"\n",
        "        self.model = tf.keras.models.load_model(filepath)\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Initialize predictor\n",
        "    predictor = JetPositionPredictor(sequence_length=10)\n",
        "\n",
        "    # Training phase\n",
        "    training_video = \"path/to/training_video.mp4\"\n",
        "    frames = predictor.extract_frames(training_video)\n",
        "    positions = predictor.detect_jet_centers(frames)\n",
        "\n",
        "    # Create sequences\n",
        "    X, y = predictor.create_sequences(positions)\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Build and train model\n",
        "    predictor.build_model(X_train.shape[1:])\n",
        "    history = predictor.train(X_train, y_train, epochs=50)\n",
        "\n",
        "    # Evaluate model\n",
        "    test_loss = predictor.model.evaluate(X_test, y_test)\n",
        "    print(f\"Test Loss: {test_loss}\")\n",
        "\n",
        "    # Save the model\n",
        "    predictor.save_model(\"jet_position_model.h5\")\n",
        "\n",
        "    # Test on new video\n",
        "    test_video = \"path/to/test_video.mp4\"\n",
        "    mse = predictor.evaluate_predictions(test_video)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "49f0WNzAqVWp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from collections import deque\n",
        "import time\n",
        "\n",
        "class RealtimeJetPredictor:\n",
        "    def __init__(self, model_path, sequence_length=10, scaler=None):\n",
        "        \"\"\"\n",
        "        Initialize real-time jet position predictor\n",
        "\n",
        "        Args:\n",
        "            model_path: Path to trained LSTM model\n",
        "            sequence_length: Length of sequence for prediction\n",
        "            scaler: Fitted scaler for normalization\n",
        "        \"\"\"\n",
        "        self.model = tf.keras.models.load_model(model_path)\n",
        "        self.sequence_length = sequence_length\n",
        "        self.scaler = scaler\n",
        "\n",
        "        # Buffer to store recent positions\n",
        "        self.position_buffer = deque(maxlen=sequence_length)\n",
        "\n",
        "        # Store predictions for visualization\n",
        "        self.predictions = []\n",
        "        self.actual_positions = []\n",
        "\n",
        "    def detect_jet_center(self, frame):\n",
        "        \"\"\"\n",
        "        Placeholder for jet center detection in a single frame\n",
        "        Replace with your actual implementation\n",
        "\n",
        "        Args:\n",
        "            frame: Video frame\n",
        "\n",
        "        Returns:\n",
        "            (x, y, z) coordinates of jet center\n",
        "        \"\"\"\n",
        "        # Replace with your actual jet detection code\n",
        "        return [0, 0, 0]  # Example placeholder\n",
        "\n",
        "    def predict_next_position(self):\n",
        "        \"\"\"\n",
        "        Predict the next position based on recent positions\n",
        "\n",
        "        Returns:\n",
        "            Predicted (x, y, z) position for next frame\n",
        "        \"\"\"\n",
        "        if len(self.position_buffer) < self.sequence_length:\n",
        "            # Not enough data for prediction\n",
        "            return None\n",
        "\n",
        "        # Prepare sequence for prediction\n",
        "        recent_positions = np.array(list(self.position_buffer))\n",
        "\n",
        "        # Scale the sequence\n",
        "        if self.scaler:\n",
        "            scaled_positions = self.scaler.transform(recent_positions)\n",
        "        else:\n",
        "            # If no scaler provided, normalize between 0-1\n",
        "            # This is less accurate than using the trained scaler\n",
        "            min_vals = np.min(recent_positions, axis=0)\n",
        "            max_vals = np.max(recent_positions, axis=0)\n",
        "            range_vals = max_vals - min_vals\n",
        "            # Avoid division by zero\n",
        "            range_vals[range_vals == 0] = 1\n",
        "            scaled_positions = (recent_positions - min_vals) / range_vals\n",
        "\n",
        "        # Reshape for prediction\n",
        "        scaled_sequence = scaled_positions.reshape(1, self.sequence_length, 3)\n",
        "\n",
        "        # Predict\n",
        "        scaled_prediction = self.model.predict(scaled_sequence, verbose=0)\n",
        "\n",
        "        # Inverse transform\n",
        "        if self.scaler:\n",
        "            prediction = self.scaler.inverse_transform(scaled_prediction)\n",
        "        else:\n",
        "            # Inverse of manual normalization\n",
        "            prediction = (scaled_prediction * range_vals) + min_vals\n",
        "\n",
        "        return prediction[0]\n",
        "\n",
        "    def process_video_stream(self, video_source=0, display=True, predict_every=1):\n",
        "        \"\"\"\n",
        "        Process video stream and make predictions\n",
        "\n",
        "        Args:\n",
        "            video_source: Camera index or video file path\n",
        "            display: Whether to display the video with predictions\n",
        "            predict_every: Make prediction every N frames\n",
        "        \"\"\"\n",
        "        cap = cv2.VideoCapture(video_source)\n",
        "        frame_count = 0\n",
        "\n",
        "        while cap.isOpened():\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            # Detect jet center in current frame\n",
        "            current_position = self.detect_jet_center(frame)\n",
        "            self.actual_positions.append(current_position)\n",
        "\n",
        "            # Add to buffer\n",
        "            self.position_buffer.append(current_position)\n",
        "\n",
        "            # Make prediction every N frames\n",
        "            if frame_count % predict_every == 0:\n",
        "                predicted_position = self.predict_next_position()\n",
        "\n",
        "                if predicted_position is not None:\n",
        "                    self.predictions.append(predicted_position)\n",
        "\n",
        "                    if display:\n",
        "                        # Draw actual position\n",
        "                        x, y, z = current_position\n",
        "                        cv2.circle(frame, (int(x), int(y)), 5, (0, 255, 0), -1)\n",
        "\n",
        "                        # Draw predicted position\n",
        "                        pred_x, pred_y, pred_z = predicted_position\n",
        "                        cv2.circle(frame, (int(pred_x), int(pred_y)), 5, (0, 0, 255), -1)\n",
        "\n",
        "                        # Add text\n",
        "                        cv2.putText(frame, f\"Actual: ({x:.1f}, {y:.1f}, {z:.1f})\",\n",
        "                                   (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
        "                        cv2.putText(frame, f\"Predicted: ({pred_x:.1f}, {pred_y:.1f}, {pred_z:.1f})\",\n",
        "                                   (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
        "\n",
        "            if display:\n",
        "                cv2.imshow('Jet Position Prediction', frame)\n",
        "\n",
        "                # Exit on 'q' press\n",
        "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "                    break\n",
        "\n",
        "            frame_count += 1\n",
        "\n",
        "        cap.release()\n",
        "        if display:\n",
        "            cv2.destroyAllWindows()\n",
        "\n",
        "        return self.actual_positions, self.predictions\n",
        "\n",
        "    def calculate_prediction_error(self):\n",
        "        \"\"\"\n",
        "        Calculate prediction error metrics\n",
        "\n",
        "        Returns:\n",
        "            Dictionary of error metrics\n",
        "        \"\"\"\n",
        "        if not self.predictions or len(self.predictions) != len(self.actual_positions[self.sequence_length:]):\n",
        "            return None\n",
        "\n",
        "        # Convert to numpy arrays\n",
        "        actual = np.array(self.actual_positions[self.sequence_length:])\n",
        "        predicted = np.array(self.predictions)\n",
        "\n",
        "        # Calculate error metrics\n",
        "        mse = np.mean(np.square(actual - predicted))\n",
        "        mae = np.mean(np.abs(actual - predicted))\n",
        "\n",
        "        return {\n",
        "            \"MSE\": mse,\n",
        "            \"MAE\": mae,\n",
        "            \"RMSE\": np.sqrt(mse)\n",
        "        }\n",
        "\n",
        "    def visualize_results(self):\n",
        "        \"\"\"\n",
        "        Visualize prediction results\n",
        "        \"\"\"\n",
        "        if not self.predictions:\n",
        "            print(\"No predictions available for visualization\")\n",
        "            return\n",
        "\n",
        "        actual = np.array(self.actual_positions[self.sequence_length:])\n",
        "        predicted = np.array(self.predictions)\n",
        "\n",
        "        # Plot results\n",
        "        dims = ['X', 'Y', 'Z']\n",
        "\n",
        "        import matplotlib.pyplot as plt\n",
        "        plt.figure(figsize=(15, 10))\n",
        "\n",
        "        for i in range(3):\n",
        "            plt.subplot(3, 1, i+1)\n",
        "            plt.plot(actual[:, i], label='Actual')\n",
        "            plt.plot(predicted[:, i], label='Predicted')\n",
        "            plt.title(f'{dims[i]} Position')\n",
        "            plt.xlabel('Frame')\n",
        "            plt.ylabel('Position')\n",
        "            plt.legend()\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('realtime_predictions.png')\n",
        "        plt.show()\n",
        "\n",
        "        # Print error metrics\n",
        "        errors = self.calculate_prediction_error()\n",
        "        if errors:\n",
        "            for metric, value in errors.items():\n",
        "                print(f\"{metric}: {value}\")\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Initialize predictor\n",
        "    predictor = RealtimeJetPredictor(\n",
        "        model_path=\"jet_position_model.h5\",\n",
        "        sequence_length=10\n",
        "    )\n",
        "\n",
        "    # Process video (use 0 for webcam or file path for video file)\n",
        "    predictor.process_video_stream(\"path/to/test_video.mp4\", display=True)\n",
        "\n",
        "    # Visualize results\n",
        "    predictor.visualize_results()"
      ],
      "metadata": {
        "id": "coGEBhIhpZAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "RlKozntQqUAB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import your existing jet detection module\n",
        "# For example:\n",
        "# from jet_detector import detect_jet_center\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from collections import deque\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "def integrate_with_existing_detector():\n",
        "    \"\"\"\n",
        "    This function shows how to integrate your existing jet detection code\n",
        "    with the LSTM prediction model\n",
        "    \"\"\"\n",
        "    # Step 1: Prepare training data using your existing detector\n",
        "    training_data = []\n",
        "\n",
        "    # Example directory of training frames\n",
        "    training_frames_dir = \"path/to/training/frames\"\n",
        "    frame_files = sorted([f for f in os.listdir(training_frames_dir) if f.endswith('.jpg')])\n",
        "\n",
        "    for frame_file in frame_files:\n",
        "        frame_path = os.path.join(training_frames_dir, frame_file)\n",
        "        frame = cv2.imread(frame_path)\n",
        "\n",
        "        # Call your existing detection function\n",
        "        # Replace this with your actual function call\n",
        "        # xyz = detect_jet_center(frame)\n",
        "        xyz = [0, 0, 0]  # Replace with your actual detection\n",
        "\n",
        "        training_data.append(xyz)\n",
        "\n",
        "    # Convert to numpy array\n",
        "    training_data = np.array(training_data)\n",
        "\n",
        "    # Step 2: Create sequences for LSTM\n",
        "    sequence_length = 10\n",
        "    X, y = [], []\n",
        "\n",
        "    # Normalize data\n",
        "    scaler = MinMaxScaler()\n",
        "    normalized_data = scaler.fit_transform(training_data)\n",
        "\n",
        "    for i in range(len(normalized_data) - sequence_length):\n",
        "        X.append(normalized_data[i:i + sequence_length])\n",
        "        y.append(normalized_data[i + sequence_length])\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "\n",
        "    # Step 3: Build and train LSTM model\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.LSTM(64, activation='relu', input_shape=(sequence_length, 3), return_sequences=True),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.LSTM(64, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.Dense(3)\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X, y, epochs=50, batch_size=32, validation_split=0.2)\n",
        "\n",
        "    # Save the model and scaler\n",
        "    model.save(\"jet_position_model.h5\")\n",
        "\n",
        "    # Step 4: Real-time prediction with feedback loop\n",
        "    def predict_with_feedback(video_path, model, scaler, sequence_length=10):\n",
        "        \"\"\"\n",
        "        Predict jet positions with feedback loop - correcting predictions\n",
        "        with actual detections\n",
        "\n",
        "        Args:\n",
        "            video_path: Path to test video\n",
        "            model: Trained LSTM model\n",
        "            scaler: Fitted scaler\n",
        "            sequence_length: Length of input sequence\n",
        "        \"\"\"\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "        # Initialize buffers\n",
        "        position_buffer = deque(maxlen=sequence_length)\n",
        "        actual_positions = []\n",
        "        predicted_positions = []\n",
        "        corrected_predictions = []\n",
        "\n",
        "        frame_count = 0\n",
        "\n",
        "        while cap.isOpened():\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            # Detect actual position\n",
        "            # Replace with your actual detection function\n",
        "            # actual_xyz = detect_jet_center(frame)\n",
        "            actual_xyz = [0, 0, 0]  # Replace with your actual detection\n",
        "\n",
        "            actual_positions.append(actual_xyz)\n",
        "\n",
        "            # If we have enough frames, make a prediction\n",
        "            if frame_count >= sequence_length:\n",
        "                # Get recent positions\n",
        "                recent_positions = np.array(list(position_buffer))\n",
        "\n",
        "                # Scale the positions\n",
        "                scaled_positions = scaler.transform(recent_positions)\n",
        "\n",
        "                # Reshape for prediction\n",
        "                scaled_sequence = scaled_positions.reshape(1, sequence_length, 3)\n",
        "\n",
        "                # Predict next position\n",
        "                scaled_prediction = model.predict(scaled_sequence, verbose=0)\n",
        "                prediction = scaler.inverse_transform(scaled_prediction)[0]\n",
        "\n",
        "                predicted_positions.append(prediction)\n",
        "\n",
        "                # Visualization (optional)\n",
        "                x, y, z = actual_xyz\n",
        "                pred_x, pred_y, pred_z = prediction\n",
        "\n",
        "                cv2.circle(frame, (int(x), int(y)), 5, (0, 255, 0), -1)  # Actual (green)\n",
        "                cv2.circle(frame, (int(pred_x), int(pred_y)), 5, (0, 0, 255), -1)  # Predicted (red)\n",
        "\n",
        "                # Calculate error\n",
        "                error = np.array(actual_xyz) - prediction\n",
        "\n",
        "                # Store for visualization\n",
        "                if len(corrected_predictions) > 0:\n",
        "                    # Previous corrected prediction\n",
        "                    prev_corrected = corrected_predictions[-1]\n",
        "\n",
        "                    # Calculate correction based on error trend\n",
        "                    alpha = 0.7  # Learning rate for correction\n",
        "                    correction = prediction + (alpha * error)\n",
        "\n",
        "                    corrected_predictions.append(correction)\n",
        "\n",
        "                    # Draw corrected prediction\n",
        "                    corr_x, corr_y, corr_z = correction\n",
        "                    cv2.circle(frame, (int(corr_x), int(corr_y)), 5, (255, 0, 0), -1)  # Corrected (blue)\n",
        "                else:\n",
        "                    # First correction is just actual position\n",
        "                    corrected_predictions.append(actual_xyz)\n",
        "\n",
        "            # Add current position to buffer\n",
        "            position_buffer.append(actual_xyz)\n",
        "\n",
        "            # Display\n",
        "            cv2.imshow('Prediction with Feedback', frame)\n",
        "            if cv2.waitKey(30) & 0xFF == ord('q'):\n",
        "                break\n",
        "\n",
        "            frame_count += 1\n",
        "\n",
        "        cap.release()\n",
        "        cv2.destroyAllWindows()\n",
        "\n",
        "        # Return results for analysis\n",
        "        return {\n",
        "            'actual': np.array(actual_positions[sequence_length:]),\n",
        "            'predicted': np.array(predicted_positions),\n",
        "            'corrected': np.array(corrected_predictions)\n",
        "        }\n",
        "\n",
        "    # Run prediction with feedback\n",
        "    results = predict_with_feedback(\n",
        "        \"path/to/test_video.mp4\",\n",
        "        model,\n",
        "        scaler,\n",
        "        sequence_length\n",
        "    )\n",
        "\n",
        "    # Analyze results\n",
        "    analyze_prediction_results(results)\n",
        "\n",
        "def analyze_prediction_results(results):\n",
        "    \"\"\"\n",
        "    Analyze prediction results and visualize\n",
        "\n",
        "    Args:\n",
        "        results: Dictionary with actual, predicted, and corrected positions\n",
        "    \"\"\"\n",
        "    actual = results['actual']\n",
        "    predicted = results['predicted']\n",
        "    corrected = results['corrected']\n",
        "\n",
        "    # Calculate error metrics\n",
        "    pred_mse = np.mean(np.square(actual - predicted))\n",
        "    corr_mse = np.mean(np.square(actual - corrected))\n",
        "\n",
        "    pred_mae = np.mean(np.abs(actual - predicted))\n",
        "    corr_mae = np.mean(np.abs(actual - corrected))\n",
        "\n",
        "    print(f\"Original Prediction MSE: {pred_mse:.4f}\")\n",
        "    print(f\"Corrected Prediction MSE: {corr_mse:.4f}\")\n",
        "    print(f\"Improvement: {100 * (1 - corr_mse/pred_mse):.2f}%\")\n",
        "\n",
        "    print(f\"Original Prediction MAE: {pred_mae:.4f}\")\n",
        "    print(f\"Corrected Prediction MAE: {corr_mae:.4f}\")\n",
        "\n",
        "    # Visualize results\n",
        "    dims = ['X', 'Y', 'Z']\n",
        "    colors = ['g', 'r', 'b']\n",
        "    labels = ['Actual', 'Predicted', 'Corrected']\n",
        "\n",
        "    plt.figure(figsize=(15, 12))\n",
        "\n",
        "    for i in range(3):\n",
        "        plt.subplot(3, 1, i+1)\n",
        "\n",
        "        plt.plot(actual[:, i], color=colors[0], label=labels[0])\n",
        "        plt.plot(predicted[:, i], color=colors[1], label=labels[1])\n",
        "        plt.plot(corrected[:, i], color=colors[2], label=labels[2])\n",
        "\n",
        "        plt.title(f'{dims[i]} Position')\n",
        "        plt.xlabel('Frame')\n",
        "        plt.ylabel('Position')\n",
        "        plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('prediction_analysis.png')\n",
        "    plt.show()\n",
        "\n",
        "    # Plot errors over time\n",
        "    plt.figure(figsize=(15, 6))\n",
        "\n",
        "    # Calculate Euclidean distance error\n",
        "    pred_error = np.sqrt(np.sum(np.square(actual - predicted), axis=1))\n",
        "    corr_error = np.sqrt(np.sum(np.square(actual - corrected), axis=1))\n",
        "\n",
        "    plt.plot(pred_error, color='r', label='Original Prediction Error')\n",
        "    plt.plot(corr_error, color='b', label='Corrected Prediction Error')\n",
        "\n",
        "    plt.title('Prediction Error Over Time')\n",
        "    plt.xlabel('Frame')\n",
        "    plt.ylabel('Euclidean Distance Error')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('prediction_error.png')\n",
        "    plt.show()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    integrate_with_existing_detector()"
      ],
      "metadata": {
        "id": "7fr0QInqqD3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload Your Video Data"
      ],
      "metadata": {
        "id": "5UunB766qR2p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()  # This will prompt you to select files"
      ],
      "metadata": {
        "id": "QaDmjvwpqHcx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Modify the Jet Detection Code"
      ],
      "metadata": {
        "id": "Su79Xh9NqSJB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile jet_detector.py\n",
        "# Paste your existing jet center detection code here\n",
        "# Ensure it has a function that takes a frame and returns (x,y,z) coordinates\n",
        "\n",
        "def detect_jet_center(frame):\n",
        "    # Your existing detection code here\n",
        "    # ...\n",
        "    return [x, y, z]  # Return center coordinates"
      ],
      "metadata": {
        "id": "_KOSbiJgqKjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Update the Predictor Class to Use Your Detector"
      ],
      "metadata": {
        "id": "1GNsnaAFqRFR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from jet_position_predictor import JetPositionPredictor\n",
        "\n",
        "# Modify the detector method to use your code\n",
        "from jet_detector import detect_jet_center\n",
        "\n",
        "# Create a subclass that uses your detection function\n",
        "class MyJetPredictor(JetPositionPredictor):\n",
        "    def detect_jet_center_in_frame(self, frame):\n",
        "        # Use your detection function\n",
        "        return detect_jet_center(frame)"
      ],
      "metadata": {
        "id": "2FOcNjQdqNlx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare Training Data"
      ],
      "metadata": {
        "id": "AOJnKTH8qQuh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize your predictor\n",
        "predictor = MyJetPredictor(sequence_length=10)\n",
        "\n",
        "# Path to your uploaded video\n",
        "training_video_path = \"your_training_video.mp4\"  # Update with actual filename\n",
        "\n",
        "# Extract frames and detect jet centers\n",
        "print(\"Extracting frames...\")\n",
        "frames = predictor.extract_frames(training_video_path)\n",
        "print(f\"Extracted {len(frames)} frames\")\n",
        "\n",
        "print(\"Detecting jet centers...\")\n",
        "positions = predictor.detect_jet_centers(frames)\n",
        "print(f\"Detected positions shape: {positions.shape}\")\n",
        "\n",
        "# Save positions to avoid recomputing them\n",
        "np.save(\"jet_positions.npy\", positions)\n",
        "\n",
        "# Alternatively, if detection takes too long, you can load previously saved positions\n",
        "# positions = np.load(\"jet_positions.npy\")"
      ],
      "metadata": {
        "id": "R9806rsXqP95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Training Sequences"
      ],
      "metadata": {
        "id": "kv3JLnraqaiB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create sequences for LSTM training\n",
        "print(\"Creating sequences...\")\n",
        "X, y = predictor.create_sequences(positions)\n",
        "print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n",
        "\n",
        "# Split data into training and validation sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "print(f\"Training samples: {X_train.shape[0]}, Validation samples: {X_val.shape[0]}\")"
      ],
      "metadata": {
        "id": "7BikKKDtqef5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build and Train the Model"
      ],
      "metadata": {
        "id": "hDRP6yUVrHOR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model\n",
        "print(\"Building model...\")\n",
        "predictor.build_model(X_train.shape[1:])\n",
        "predictor.model.summary()\n",
        "\n",
        "# Train the model\n",
        "print(\"Training model...\")\n",
        "history = predictor.train(\n",
        "    X_train, y_train,\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "# Plot training history\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['mae'])\n",
        "plt.plot(history.history['val_mae'])\n",
        "plt.title('Model MAE')\n",
        "plt.ylabel('MAE')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eZN36C_6qfnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Evaluate on Validation Set"
      ],
      "metadata": {
        "id": "Bx9JULZkrLHp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model on validation set\n",
        "val_loss, val_mae = predictor.model.evaluate(X_val, y_val)\n",
        "print(f\"Validation Loss: {val_loss:.4f}\")\n",
        "print(f\"Validation MAE: {val_mae:.4f}\")\n",
        "\n",
        "# Make predictions on validation set\n",
        "val_pred = predictor.model.predict(X_val)\n",
        "\n",
        "# Plot predictions vs actual for first few validation samples\n",
        "plt.figure(figsize=(15, 10))\n",
        "sample_idx = 0  # Change this to view different samples\n",
        "\n",
        "for i in range(3):  # Plot X, Y, Z separately\n",
        "    plt.subplot(3, 1, i+1)\n",
        "    plt.plot(y_val[sample_idx, i], 'g-', label=f'Actual')\n",
        "    plt.plot(val_pred[sample_idx, i], 'r--', label=f'Predicted')\n",
        "    plt.title(f'Dimension {i} ({\"XYZ\"[i]})')\n",
        "    plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7R5w-EYrqh_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the Trained Model"
      ],
      "metadata": {
        "id": "qDqVtz5vrPDZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model\n",
        "predictor.save_model(\"jet_position_model.h5\")\n",
        "print(\"Model saved successfully\")\n",
        "\n",
        "# Save the scaler too (needed for future predictions)\n",
        "import pickle\n",
        "with open('scaler.pkl', 'wb') as f:\n",
        "    pickle.dump(predictor.scaler, f)\n",
        "print(\"Scaler saved successfully\")"
      ],
      "metadata": {
        "id": "_fDqZM54qnM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test on a New Video"
      ],
      "metadata": {
        "id": "dVOLoYWzrRlS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to test video\n",
        "test_video_path = \"your_test_video.mp4\"  # Update with actual filename\n",
        "\n",
        "# Import RealtimeJetPredictor\n",
        "from realtime_prediction import RealtimeJetPredictor\n",
        "\n",
        "# Create a subclass with your detection code\n",
        "class MyRealtimePredictor(RealtimeJetPredictor):\n",
        "    def detect_jet_center(self, frame):\n",
        "        # Use your detection function\n",
        "        return detect_jet_center(frame)\n",
        "\n",
        "# Load the saved scaler\n",
        "with open('scaler.pkl', 'rb') as f:\n",
        "    scaler = pickle.load(f)\n",
        "\n",
        "# Initialize real-time predictor\n",
        "rt_predictor = MyRealtimePredictor(\n",
        "    model_path=\"jet_position_model.h5\",\n",
        "    sequence_length=10,\n",
        "    scaler=scaler\n",
        ")\n",
        "\n",
        "# Process the test video\n",
        "actual_positions, predictions = rt_predictor.process_video_stream(\n",
        "    test_video_path,\n",
        "    display=True,\n",
        "    predict_every=1\n",
        ")\n",
        "\n",
        "# Visualize results\n",
        "rt_predictor.visualize_results()\n",
        "\n",
        "# Calculate prediction errors\n",
        "error_metrics = rt_predictor.calculate_prediction_error()\n",
        "for metric, value in error_metrics.items():\n",
        "    print(f\"{metric}: {value:.4f}\")"
      ],
      "metadata": {
        "id": "NPNyFz8UqpDp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
